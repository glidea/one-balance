#!/usr/bin/env node

// æµ‹è¯• OpenAI å…¼å®¹æ ¼å¼å’Œä¸­æ–‡ç¼–ç 
//
// é…ç½®ä¼˜å…ˆçº§: ç¯å¢ƒå˜é‡ > .envæ–‡ä»¶ > é»˜è®¤å€¼
//
// ä½¿ç”¨æ–¹æ³•:
//   1. ä» .env æ–‡ä»¶åŠ è½½é…ç½®: node tests/test-openai-compat.mjs (ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ)
//   2. å‘½ä»¤è¡Œä¼ å‚: WORKER_URL=https://your-worker.workers.dev AUTH_KEY=your-secret-key node tests/test-openai-compat.mjs
//   3. å¯¼å…¥ç¯å¢ƒå˜é‡: source .env && node tests/test-openai-compat.mjs
//
// æ³¨æ„ï¼šæ­¤è„šæœ¬ä½¿ç”¨ ES Modulesï¼Œéœ€è¦ Node.js 14+ æ”¯æŒ

import { loadTestConfig, validateConfig, printConfig, makeAuthenticatedRequest, TestRunner } from './test-utils.mjs'

async function testNonStreamRequest(config) {
    const { WORKER_URL, AUTH_KEY } = config

    const response = await makeAuthenticatedRequest(WORKER_URL, AUTH_KEY, '/api/compat/chat/completions', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model: 'google-ai-studio/gemini-2.0-flash',
            messages: [
                {
                    role: 'system',
                    content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚'
                },
                {
                    role: 'user',
                    content: 'ä½ å¥½ï¼è¯·ç”¨ä¸­æ–‡ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²ã€‚è¯·ä¿æŒå›ç­”ç®€æ´ï¼Œå¤§çº¦100å­—ã€‚'
                }
            ],
            max_tokens: 150,
            temperature: 0.7
        })
    })

    if (!response.ok) {
        console.error('âŒ è¯·æ±‚å¤±è´¥:', response.status, await response.text())
        return false
    }

    const data = await response.json()
    console.log('âœ… éæµå¼å“åº”æˆåŠŸ')
    console.log('ğŸ“ å“åº”å†…å®¹:', data.choices[0].message.content)
    console.log('ğŸ“Š Token ä½¿ç”¨:', data.usage)

    return true
}

async function testStreamRequest(config) {
    const { WORKER_URL, AUTH_KEY } = config

    const response = await makeAuthenticatedRequest(WORKER_URL, AUTH_KEY, '/api/compat/chat/completions', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model: 'google-ai-studio/gemini-2.0-flash',
            messages: [
                {
                    role: 'user',
                    content: 'è¯·ç”¨ä¸­æ–‡å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„çŸ­è¯—ï¼Œ4è¡Œå³å¯ã€‚'
                }
            ],
            stream: true,
            max_tokens: 100,
            temperature: 0.8
        })
    })

    if (!response.ok) {
        console.error('âŒ æµå¼è¯·æ±‚å¤±è´¥:', response.status, await response.text())
        return false
    }

    console.log('âœ… æµå¼å“åº”å¼€å§‹')
    console.log('ğŸ“ æµå¼å†…å®¹:')

    const reader = response.body.getReader()
    const decoder = new TextDecoder()
    let fullContent = ''

    try {
        while (true) {
            const { done, value } = await reader.read()
            if (done) break

            const chunk = decoder.decode(value)
            const lines = chunk.split('\n')

            for (const line of lines) {
                if (line.startsWith('data: ')) {
                    const data = line.slice(6).trim()
                    if (data === '[DONE]') {
                        console.log('\nğŸ æµå¼å“åº”å®Œæˆ')
                        return true
                    }

                    try {
                        const parsed = JSON.parse(data)
                        const content = parsed.choices?.[0]?.delta?.content
                        if (content) {
                            process.stdout.write(content)
                            fullContent += content
                        }
                    } catch (e) {
                        // å¿½ç•¥è§£æé”™è¯¯
                    }
                }
            }
        }
    } finally {
        reader.releaseLock()
    }

    console.log(`\nğŸ“Š å®Œæ•´å†…å®¹é•¿åº¦: ${fullContent.length} å­—ç¬¦`)
    return true
}

async function testChineseEncoding(config) {
    const { WORKER_URL, AUTH_KEY } = config

    const testCases = [
        'ä½ å¥½ä¸–ç•Œï¼è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡æµ‹è¯•ã€‚',
        'ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ï¼šï¼Œã€‚ï¼Ÿï¼ï¼›ï¼š""ï¼ˆï¼‰ã€ã€‘',
        'æ•°å­—å’Œä¸­æ–‡æ··åˆï¼š2024å¹´æ˜¯é¾™å¹´ï¼Œç¥å¤§å®¶æ–°å¹´å¿«ä¹ï¼',
        'ä¸­è‹±æ··åˆï¼šHelloä¸–ç•Œï¼Œè¿™æ˜¯mixed languageæµ‹è¯•ã€‚'
    ]

    let passedCases = 0

    for (let i = 0; i < testCases.length; i++) {
        const testInput = testCases[i]
        console.log(`\nğŸ“ æµ‹è¯•ç”¨ä¾‹ ${i + 1}: ${testInput}`)

        try {
            const response = await makeAuthenticatedRequest(WORKER_URL, AUTH_KEY, '/api/compat/chat/completions', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: 'google-ai-studio/gemini-2.0-flash',
                    messages: [
                        {
                            role: 'user',
                            content: `è¯·ç›´æ¥å¤è¿°è¿™æ®µæ–‡å­—ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ï¼š${testInput}`
                        }
                    ],
                    max_tokens: 100
                })
            })

            if (response.ok) {
                const data = await response.json()
                const output = data.choices[0].message.content
                console.log(`âœ… è¾“å‡º: ${output}`)

                // ç®€å•æ£€æŸ¥æ˜¯å¦åŒ…å«åŸå§‹ä¸­æ–‡å†…å®¹
                const hasOriginalContent = testInput.split('').some(char => output.includes(char))
                if (hasOriginalContent) {
                    console.log('âœ… ä¸­æ–‡ç¼–ç æ­£å¸¸')
                    passedCases++
                } else {
                    console.log('âš ï¸  ä¸­æ–‡ç¼–ç å¯èƒ½å­˜åœ¨é—®é¢˜')
                }
            } else {
                console.log('âŒ è¯·æ±‚å¤±è´¥:', response.status)
            }
        } catch (error) {
            console.log('âŒ è¯·æ±‚å‡ºé”™:', error.message)
        }
    }

    return passedCases === testCases.length
}

async function testModelsEndpoint(config) {
    const { WORKER_URL, AUTH_KEY } = config

    const response = await makeAuthenticatedRequest(WORKER_URL, AUTH_KEY, '/api/compat/models')

    if (!response.ok) {
        console.error('âŒ æ¨¡å‹åˆ—è¡¨è¯·æ±‚å¤±è´¥:', response.status, await response.text())
        return false
    }

    const data = await response.json()
    console.log('âœ… æ¨¡å‹åˆ—è¡¨å“åº”æˆåŠŸ')
    console.log('ğŸ“ å¯ç”¨æ¨¡å‹æ•°é‡:', data.data?.length || 0)
    if (data.data && data.data.length > 0) {
        console.log(
            'ğŸ“‹ æ¨¡å‹ç¤ºä¾‹:',
            data.data.slice(0, 3).map(m => m.id)
        )
    }
    console.log('ğŸ“Š å“åº”æ ¼å¼:', data.object)

    return true
}

async function main() {
    console.log('ğŸš€ å¼€å§‹æµ‹è¯• OpenAI å…¼å®¹æ ¼å¼å’Œä¸­æ–‡ç¼–ç ...')

    // åŠ è½½é…ç½®
    const config = loadTestConfig()

    // éªŒè¯é…ç½®
    if (!validateConfig(config)) {
        process.exit(1)
    }

    // æ‰“å°é…ç½®ä¿¡æ¯
    printConfig(config)

    // åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    const runner = new TestRunner('OpenAIå…¼å®¹æ€§æµ‹è¯•')

    try {
        // æ‰§è¡Œå„é¡¹æµ‹è¯•
        await runner.run('æ¨¡å‹åˆ—è¡¨ç«¯ç‚¹', () => testModelsEndpoint(config))
        await runner.run('éæµå¼è¯·æ±‚', () => testNonStreamRequest(config))
        await runner.run('æµå¼è¯·æ±‚', () => testStreamRequest(config))
        await runner.run('ä¸­æ–‡ç¼–ç ', () => testChineseEncoding(config))

        // æ‰“å°ç»“æœå¹¶é€€å‡º
        const success = runner.printResults()
        process.exit(success ? 0 : 1)
    } catch (error) {
        console.error('âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:', error)
        process.exit(1)
    }
}

main()
